#!/usr/bin/env python3
"""
MIMIC-IIIä¸“å®¶å†³ç­–æå–å™¨
ä»çœŸå®åŒ»ç–—æ•°æ®ä¸­æå–åŒ»ç”Ÿçš„æ²»ç–—å†³ç­–ï¼Œç”¨äºç›‘ç£å­¦ä¹ 
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import json
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

class MIMICExpertDecisionExtractor:
    """ä»MIMIC-IIIæ•°æ®æå–ä¸“å®¶å†³ç­–"""
    
    def __init__(self, raw_data_dir, output_dir):
        self.raw_data_dir = Path(raw_data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºä¸“å®¶æ•°æ®ç›®å½•
        self.expert_data_dir = self.output_dir / "expert_data"
        self.expert_data_dir.mkdir(exist_ok=True)
        
        # è¯ç‰©åˆ°åŠ¨ä½œçš„æ˜ å°„
        self.drug_action_mapping = self._create_drug_action_mapping()
        
        # æ•°æ®ç¼“å­˜
        self.medications_cache = None
        self.vital_signs_cache = None
        self.demographics_cache = None
        
    def _create_drug_action_mapping(self):
        """åˆ›å»ºè¯ç‰©åˆ°æ²»ç–—åŠ¨ä½œçš„æ˜ å°„"""
        return {
            # 0: è§‚å¯Ÿ/ç»´æŒæ²»ç–—
            'observation': 0,
            
            # 1-4: å¿ƒè¡€ç®¡ç³»ç»Ÿè¯ç‰©
            'vasopressor': 1,       # è¡€ç®¡åŠ å‹è¯
            'antihypertensive': 2,  # é™å‹è¯  
            'diuretic': 3,          # åˆ©å°¿å‰‚
            'beta_blocker': 4,      # Î²å—ä½“é˜»æ»å‰‚
            
            # 5-8: å‘¼å¸ç³»ç»Ÿ
            'oxygen_therapy': 5,    # æ°§ç–—
            'bronchodilator': 6,    # æ”¯æ°”ç®¡æ‰©å¼ å‰‚
            'steroid': 7,           # ç±»å›ºé†‡
            'ventilation': 8,       # æœºæ¢°é€šæ°”
            
            # 9-12: ä»£è°¢æ”¯æŒ
            'insulin': 9,           # èƒ°å²›ç´ 
            'glucose': 10,          # è‘¡è„ç³–
            'electrolyte': 11,      # ç”µè§£è´¨è¡¥å……
            'nutrition': 12,        # è¥å…»æ”¯æŒ
            
            # 13-16: æ„ŸæŸ“æ§åˆ¶
            'antibiotic': 13,       # æŠ—ç”Ÿç´ 
            'antifungal': 14,       # æŠ—çœŸèŒ
            'antiviral': 15,        # æŠ—ç—…æ¯’
            'antiseptic': 16,       # é˜²è…å‰‚
            
            # 17-19: å…¶ä»–æ²»ç–—
            'analgesic': 17,        # é•‡ç—›å‰‚
            'sedative': 18,         # é•‡é™å‰‚
            'anticoagulant': 19     # æŠ—å‡å‰‚
        }
    
    def _map_drug_to_action(self, drug_name):
        """å°†è¯ç‰©åç§°æ˜ å°„åˆ°åŠ¨ä½œID"""
        drug_name = drug_name.lower() if drug_name else ""
        
        # è¡€ç®¡åŠ å‹è¯
        if any(word in drug_name for word in ['norepinephrine', 'epinephrine', 'dopamine', 'vasopressin', 'phenylephrine']):
            return self.drug_action_mapping['vasopressor']
        
        # é™å‹è¯
        elif any(word in drug_name for word in ['lisinopril', 'amlodipine', 'losartan', 'hydralazine', 'nifedipine']):
            return self.drug_action_mapping['antihypertensive']
        
        # åˆ©å°¿å‰‚
        elif any(word in drug_name for word in ['furosemide', 'hydrochlorothiazide', 'spironolactone', 'torsemide']):
            return self.drug_action_mapping['diuretic']
        
        # Î²å—ä½“é˜»æ»å‰‚
        elif any(word in drug_name for word in ['metoprolol', 'propranolol', 'atenolol', 'carvedilol', 'esmolol']):
            return self.drug_action_mapping['beta_blocker']
        
        # èƒ°å²›ç´ 
        elif any(word in drug_name for word in ['insulin']):
            return self.drug_action_mapping['insulin']
        
        # è‘¡è„ç³–/ç³–æ°´
        elif any(word in drug_name for word in ['dextrose', 'd5w', 'glucose', '5% dextrose']):
            return self.drug_action_mapping['glucose']
        
        # ç”µè§£è´¨
        elif any(word in drug_name for word in ['potassium', 'magnesium', 'calcium', 'phosphate', 'sodium chloride']):
            return self.drug_action_mapping['electrolyte']
        
        # æŠ—ç”Ÿç´ 
        elif any(word in drug_name for word in ['vancomycin', 'piperacillin', 'ceftriaxone', 'levofloxacin', 'meropenem']):
            return self.drug_action_mapping['antibiotic']
        
        # é•‡ç—›å‰‚
        elif any(word in drug_name for word in ['morphine', 'fentanyl', 'acetaminophen', 'oxycodone']):
            return self.drug_action_mapping['analgesic']
        
        # é•‡é™å‰‚
        elif any(word in drug_name for word in ['propofol', 'midazolam', 'lorazepam', 'dexmedetomidine']):
            return self.drug_action_mapping['sedative']
        
        # æŠ—å‡å‰‚
        elif any(word in drug_name for word in ['heparin', 'warfarin', 'enoxaparin']):
            return self.drug_action_mapping['anticoagulant']
        
        # ç±»å›ºé†‡
        elif any(word in drug_name for word in ['hydrocortisone', 'methylprednisolone', 'prednisone']):
            return self.drug_action_mapping['steroid']
        
        # é»˜è®¤ä¸ºè§‚å¯Ÿ
        else:
            return self.drug_action_mapping['observation']
    
    def load_raw_data(self):
        """åŠ è½½åŸå§‹MIMIC-IIIæ•°æ®"""
        print("ğŸ“Š åŠ è½½MIMIC-IIIåŸå§‹æ•°æ®...")
        
        # åŠ è½½è¯ç‰©æ•°æ®
        print("  - åŠ è½½è¯ç‰©æ•°æ®...")
        medications_file = self.raw_data_dir / "top 1000 medications_mimic3.csv"
        self.medications_cache = pd.read_csv(medications_file)
        print(f"    è¯ç‰©è®°å½•: {len(self.medications_cache):,} æ¡")
        
        # åŠ è½½ç”Ÿå‘½ä½“å¾æ•°æ®
        print("  - åŠ è½½ç”Ÿå‘½ä½“å¾æ•°æ®...")
        vital_signs_file = self.raw_data_dir / "time series variables(vital signs)_mimic3.csv"
        # ç”±äºæ–‡ä»¶å¾ˆå¤§ï¼Œåªè¯»å–ä¸€éƒ¨åˆ†ç”¨äºç¤ºä¾‹
        vital_signs_chunk = pd.read_csv(vital_signs_file, nrows=500000)  # è¯»å–50ä¸‡è¡Œä½œä¸ºç¤ºä¾‹
        self.vital_signs_cache = vital_signs_chunk
        print(f"    ç”Ÿå‘½ä½“å¾è®°å½•: {len(self.vital_signs_cache):,} æ¡ (ç¤ºä¾‹æ•°æ®)")
        
        # åŠ è½½äººå£ç»Ÿè®¡å­¦æ•°æ®
        print("  - åŠ è½½äººå£ç»Ÿè®¡å­¦æ•°æ®...")
        demographics_file = self.raw_data_dir / "static variables(demographics)_mimic3.csv"
        self.demographics_cache = pd.read_csv(demographics_file)
        print(f"    äººå£ç»Ÿè®¡å­¦è®°å½•: {len(self.demographics_cache):,} æ¡")
        
        print("âœ… æ•°æ®åŠ è½½å®Œæˆ!")
    
    def extract_expert_decisions(self, max_patients=100, time_window_hours=6):
        """æå–ä¸“å®¶å†³ç­–æ•°æ®"""
        print(f"ğŸ” å¼€å§‹æå–ä¸“å®¶å†³ç­– (æœ€å¤š{max_patients}ä¸ªæ‚£è€…, æ—¶é—´çª—å£{time_window_hours}å°æ—¶)...")
        
        if self.medications_cache is None:
            self.load_raw_data()
        
        expert_decisions = []
        processed_patients = 0
        
        # é¢„å¤„ç†æ•°æ®
        self._preprocess_data()
        
        # è·å–æœ‰é‡å æ•°æ®çš„æ‚£è€…
        medication_patients = set(self.medications_cache['SUBJECT_ID'].unique())
        vital_signs_patients = set(self.vital_signs_cache['subject_id'].unique())
        common_patients = list(medication_patients & vital_signs_patients)
        
        print(f"  - æ‰¾åˆ° {len(common_patients)} ä¸ªæœ‰å®Œæ•´æ•°æ®çš„æ‚£è€…")
        
        # é™åˆ¶å¤„ç†çš„æ‚£è€…æ•°é‡
        if max_patients:
            common_patients = common_patients[:max_patients]
        
        for patient_id in common_patients:
            if processed_patients >= max_patients:
                break
                
            try:
                patient_decisions = self._extract_patient_decisions(
                    patient_id, time_window_hours
                )
                expert_decisions.extend(patient_decisions)
                processed_patients += 1
                
                if processed_patients % 10 == 0:
                    print(f"    å·²å¤„ç† {processed_patients}/{max_patients} ä¸ªæ‚£è€…, "
                          f"æå–å†³ç­– {len(expert_decisions)} ä¸ª")
                    
            except Exception as e:
                print(f"    âš ï¸ å¤„ç†æ‚£è€… {patient_id} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… ä¸“å®¶å†³ç­–æå–å®Œæˆ! æ€»è®¡ {len(expert_decisions)} ä¸ªå†³ç­–")
        return expert_decisions
    
    def _preprocess_data(self):
        """é¢„å¤„ç†æ•°æ®"""
        # è½¬æ¢æ—¶é—´æ ¼å¼
        self.medications_cache['STARTDATE'] = pd.to_datetime(
            self.medications_cache['STARTDATE'], errors='coerce'
        )
        self.vital_signs_cache['charttime'] = pd.to_datetime(
            self.vital_signs_cache['charttime'], errors='coerce'
        )
        
        # ç§»é™¤æ— æ•ˆæ—¶é—´æ•°æ®
        self.medications_cache = self.medications_cache.dropna(subset=['STARTDATE'])
        self.vital_signs_cache = self.vital_signs_cache.dropna(subset=['charttime'])
        
        # æ’åº
        self.medications_cache = self.medications_cache.sort_values(['SUBJECT_ID', 'STARTDATE'])
        self.vital_signs_cache = self.vital_signs_cache.sort_values(['subject_id', 'charttime'])
    
    def _extract_patient_decisions(self, patient_id, time_window_hours):
        """æå–å•ä¸ªæ‚£è€…çš„ä¸“å®¶å†³ç­–"""
        patient_decisions = []
        
        # è·å–æ‚£è€…çš„è¯ç‰©å’Œç”Ÿå‘½ä½“å¾æ•°æ®
        patient_meds = self.medications_cache[
            self.medications_cache['SUBJECT_ID'] == patient_id
        ].copy()
        
        patient_vitals = self.vital_signs_cache[
            self.vital_signs_cache['subject_id'] == patient_id
        ].copy()
        
        if len(patient_meds) == 0 or len(patient_vitals) == 0:
            return patient_decisions
        
        # ä¸ºæ¯ä¸ªç”¨è¯å†³ç­–æ‰¾åˆ°å¯¹åº”çš„çŠ¶æ€
        for _, med_record in patient_meds.iterrows():
            drug_time = med_record['STARTDATE']
            drug_name = med_record['DRUG']
            
            # è·³è¿‡æ— æ•ˆè¯ç‰©è®°å½•
            if pd.isna(drug_time) or not drug_name:
                continue
            
            # æ˜ å°„è¯ç‰©åˆ°åŠ¨ä½œ
            action = self._map_drug_to_action(drug_name)
            
            # è·å–ç”¨è¯å‰çš„ç”Ÿå‘½ä½“å¾çŠ¶æ€
            time_cutoff = drug_time - timedelta(hours=time_window_hours)
            relevant_vitals = patient_vitals[
                (patient_vitals['charttime'] >= time_cutoff) & 
                (patient_vitals['charttime'] <= drug_time)
            ]
            
            if len(relevant_vitals) == 0:
                continue
            
            # æå–çŠ¶æ€ç‰¹å¾
            state_features = self._extract_state_features(relevant_vitals)
            
            if state_features is not None:
                patient_decisions.append({
                    'patient_id': patient_id,
                    'timestamp': drug_time,
                    'drug_name': drug_name,
                    'action': action,
                    'state_features': state_features,
                    'vital_signs_count': len(relevant_vitals)
                })
        
        return patient_decisions
    
    def _extract_state_features(self, vitals_data):
        """ä»ç”Ÿå‘½ä½“å¾æ•°æ®æå–çŠ¶æ€ç‰¹å¾"""
        try:
            # é‡è¦çš„ç”Ÿå‘½ä½“å¾æ ‡ç­¾
            important_labels = [
                'Temperature F', 'Temperature C',
                'Heart Rate', 'Respiratory Rate',
                'Arterial Blood Pressure systolic',
                'Arterial Blood Pressure diastolic', 
                'O2 saturation pulseoxymetry',
                'GCS - Eye Opening',
                'GCS - Motor Response', 
                'GCS - Verbal Response'
            ]
            
            features = {}
            
            for label in important_labels:
                label_data = vitals_data[vitals_data['label'] == label]
                if len(label_data) > 0:
                    # ä½¿ç”¨æœ€æ–°çš„å€¼
                    latest_value = label_data.iloc[-1]['valuenum']
                    if pd.notna(latest_value):
                        features[label.lower().replace(' ', '_').replace('-', '_')] = latest_value
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç‰¹å¾
            if len(features) < 5:  # è‡³å°‘éœ€è¦5ä¸ªæœ‰æ•ˆç‰¹å¾
                return None
            
            # å¡«å……ç¼ºå¤±ç‰¹å¾çš„é»˜è®¤å€¼
            feature_defaults = {
                'temperature_f': 98.6,
                'temperature_c': 37.0,
                'heart_rate': 80,
                'respiratory_rate': 16,
                'arterial_blood_pressure_systolic': 120,
                'arterial_blood_pressure_diastolic': 80,
                'o2_saturation_pulseoxymetry': 98,
                'gcs___eye_opening': 4,
                'gcs___motor_response': 6,
                'gcs___verbal_response': 5
            }
            
            # ä½¿ç”¨åæ°åº¦è½¬æ‘„æ°åº¦
            if 'temperature_f' in features and 'temperature_c' not in features:
                features['temperature_c'] = (features['temperature_f'] - 32) * 5/9
            elif 'temperature_c' not in features and 'temperature_f' not in features:
                features['temperature_c'] = feature_defaults['temperature_c']
            
            # å¡«å……å…¶ä»–ç¼ºå¤±å€¼
            for key, default_val in feature_defaults.items():
                if key not in features and key != 'temperature_f':
                    features[key] = default_val
            
            # è½¬æ¢ä¸ºå‘é‡æ ¼å¼ (ä¸å½“å‰æ¨¡å‹è¾“å…¥ä¸€è‡´)
            feature_vector = [
                features.get('temperature_c', 37.0),
                features.get('heart_rate', 80),
                features.get('respiratory_rate', 16),
                features.get('arterial_blood_pressure_systolic', 120),
                features.get('arterial_blood_pressure_diastolic', 80),
                features.get('o2_saturation_pulseoxymetry', 98),
                0,  # å ä½ç¬¦ (glucoseç­‰å…¶ä»–ç‰¹å¾)
                features.get('gcs___eye_opening', 4),
                features.get('gcs___motor_response', 6),
                features.get('gcs___verbal_response', 5),
                35,  # ageå ä½ç¬¦
                0   # sofa_scoreå ä½ç¬¦
            ]
            
            return np.array(feature_vector)
            
        except Exception as e:
            print(f"      ç‰¹å¾æå–é”™è¯¯: {e}")
            return None
    
    def save_expert_decisions(self, expert_decisions):
        """ä¿å­˜ä¸“å®¶å†³ç­–æ•°æ®"""
        print("ğŸ’¾ ä¿å­˜ä¸“å®¶å†³ç­–æ•°æ®...")
        
        if not expert_decisions:
            print("âŒ æ²¡æœ‰ä¸“å®¶å†³ç­–æ•°æ®å¯ä¿å­˜")
            return
        
        # è½¬æ¢ä¸ºDataFrame
        decisions_df = []
        for decision in expert_decisions:
            row = {
                'patient_id': decision['patient_id'],
                'timestamp': decision['timestamp'],
                'drug_name': decision['drug_name'],
                'expert_action': decision['action'],
                'vital_signs_count': decision['vital_signs_count']
            }
            
            # æ·»åŠ çŠ¶æ€ç‰¹å¾
            state_features = decision['state_features']
            feature_names = [
                'temperature', 'heart_rate', 'respiratory_rate',
                'bp_systolic', 'bp_diastolic', 'spo2', 'glucose',
                'gcs_eye', 'gcs_motor', 'gcs_verbal', 'age', 'sofa_score'
            ]
            
            for i, feature_name in enumerate(feature_names):
                if i < len(state_features):
                    row[feature_name] = state_features[i]
                else:
                    row[feature_name] = 0
            
            decisions_df.append(row)
        
        df = pd.DataFrame(decisions_df)
        
        # ä¿å­˜åˆ°CSV
        csv_path = self.expert_data_dir / "expert_decisions.csv"
        df.to_csv(csv_path, index=False)
        print(f"âœ… ä¸“å®¶å†³ç­–å·²ä¿å­˜åˆ°: {csv_path}")
        
        # ä¿å­˜ä¸ºpickleæ ¼å¼
        pickle_path = self.expert_data_dir / "expert_decisions.pkl"
        with open(pickle_path, 'wb') as f:
            pickle.dump(expert_decisions, f)
        print(f"âœ… ä¸“å®¶å†³ç­–å·²ä¿å­˜åˆ°: {pickle_path}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_statistics_report(df)
        
        return csv_path
    
    def _generate_statistics_report(self, decisions_df):
        """ç”Ÿæˆä¸“å®¶å†³ç­–ç»Ÿè®¡æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        
        stats = {
            'total_decisions': len(decisions_df),
            'unique_patients': decisions_df['patient_id'].nunique(),
            'action_distribution': decisions_df['expert_action'].value_counts().to_dict(),
            'drug_distribution': decisions_df['drug_name'].value_counts().head(20).to_dict(),
            'feature_statistics': {}
        }
        
        # ç‰¹å¾ç»Ÿè®¡
        feature_cols = ['temperature', 'heart_rate', 'respiratory_rate', 
                       'bp_systolic', 'bp_diastolic', 'spo2']
        
        for col in feature_cols:
            if col in decisions_df.columns:
                stats['feature_statistics'][col] = {
                    'mean': float(decisions_df[col].mean()),
                    'std': float(decisions_df[col].std()),
                    'min': float(decisions_df[col].min()),
                    'max': float(decisions_df[col].max())
                }
        
        # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
        stats_path = self.expert_data_dir / "expert_decisions_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {stats_path}")
        
        # æ‰“å°ç®€è¦ç»Ÿè®¡
        print("\nğŸ“ˆ ä¸“å®¶å†³ç­–ç»Ÿè®¡æ‘˜è¦:")
        print(f"  - æ€»å†³ç­–æ•°: {stats['total_decisions']:,}")
        print(f"  - æ‚£è€…æ•°: {stats['unique_patients']:,}")
        print(f"  - åŠ¨ä½œåˆ†å¸ƒ:")
        for action, count in sorted(stats['action_distribution'].items()):
            percentage = count / stats['total_decisions'] * 100
            print(f"    åŠ¨ä½œ {action}: {count:,} ({percentage:.1f}%)")
    
    def run_extraction(self, max_patients=100, time_window_hours=6):
        """è¿è¡Œå®Œæ•´çš„ä¸“å®¶å†³ç­–æå–æµç¨‹"""
        print("ğŸš€ å¼€å§‹MIMIC-IIIä¸“å®¶å†³ç­–æå–æµç¨‹...")
        print(f"å‚æ•°: æœ€å¤§æ‚£è€…æ•°={max_patients}, æ—¶é—´çª—å£={time_window_hours}å°æ—¶")
        
        try:
            # 1. åŠ è½½æ•°æ®
            self.load_raw_data()
            
            # 2. æå–ä¸“å®¶å†³ç­–
            expert_decisions = self.extract_expert_decisions(
                max_patients=max_patients,
                time_window_hours=time_window_hours
            )
            
            # 3. ä¿å­˜ç»“æœ
            if expert_decisions:
                csv_path = self.save_expert_decisions(expert_decisions)
                print(f"\nğŸ‰ ä¸“å®¶å†³ç­–æå–å®Œæˆ!")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {csv_path}")
                return csv_path
            else:
                print("âŒ æœªæå–åˆ°ä»»ä½•ä¸“å®¶å†³ç­–")
                return None
                
        except Exception as e:
            print(f"âŒ ä¸“å®¶å†³ç­–æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®è·¯å¾„
    current_dir = Path(__file__).parent
    raw_data_dir = current_dir.parent / "raw_data" / "mimic3_original"
    output_dir = current_dir.parent / "processed_data"
    
    # æ£€æŸ¥åŸå§‹æ•°æ®ç›®å½•
    if not raw_data_dir.exists():
        print(f"âŒ åŸå§‹æ•°æ®ç›®å½•ä¸å­˜åœ¨: {raw_data_dir}")
        return
    
    # åˆ›å»ºæå–å™¨
    extractor = MIMICExpertDecisionExtractor(raw_data_dir, output_dir)
    
    # è¿è¡Œæå–
    result_path = extractor.run_extraction(
        max_patients=100,      # å¤„ç†100ä¸ªæ‚£è€…ä½œä¸ºç¤ºä¾‹
        time_window_hours=6    # 6å°æ—¶çš„æ—¶é—´çª—å£
    )
    
    if result_path:
        print(f"\nâœ… ä¸“å®¶å†³ç­–æ•°æ®å·²å‡†å¤‡å°±ç»ª!")
        print(f"ğŸ“‚ æ•°æ®æ–‡ä»¶: {result_path}")
        print("ğŸ”„ ç°åœ¨å¯ä»¥åœ¨è®­ç»ƒä¸­ä½¿ç”¨çœŸå®ä¸“å®¶æ•°æ®äº†!")
    else:
        print("\nâŒ ä¸“å®¶å†³ç­–æå–å¤±è´¥")

if __name__ == "__main__":
    main()
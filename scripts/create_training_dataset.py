#!/usr/bin/env python3
"""
åˆ›å»ºæœ€ç»ˆè®­ç»ƒæ•°æ®é›†
å°†è¯ç‰©actionæ•°æ®ä¸merged datasetåˆå¹¶
"""

import pandas as pd
import numpy as np
import json
# from tqdm import tqdm  # ç§»é™¤tqdmä¾èµ–
import os

# æ–‡ä»¶è·¯å¾„
MERGED_DATA_CSV = "/Users/lulingwei/Desktop/TUM/sem_2/reinforcement learning/ä»£ç /sepsis_rl_system/data/processed/merged_dataset.csv"
PRES_CSV = "/Users/lulingwei/Desktop/TUM/sem_2/reinforcement learning/ä»£ç /sepsis_rl_system/data/processed/cleaned_prescriptions.csv"
DRUG_MAP_JSON = "/Users/lulingwei/Desktop/TUM/sem_2/reinforcement learning/ä»£ç /sepsis_rl_system/scripts/improved_drug_map.json"
DRUG_IDX_JSON = "/Users/lulingwei/Desktop/TUM/sem_2/reinforcement learning/ä»£ç /sepsis_rl_system/scripts/improved_drug_idx.json"
OUTPUT_CSV = "/Users/lulingwei/Desktop/TUM/sem_2/reinforcement learning/ä»£ç /sepsis_rl_system/data/processed/training_dataset.csv"

print("=" * 60)
print("åˆ›å»ºæœ€ç»ˆè®­ç»ƒæ•°æ®é›†")
print("=" * 60)

# æ­¥éª¤1ï¼šè¯»å–æ•°æ®
print("\nğŸ“¥ æ­¥éª¤1ï¼šè¯»å–æ•°æ®")
print("è¯»å–merged dataset...")
state_data = pd.read_csv(MERGED_DATA_CSV)
print(f"State data shape: {state_data.shape}")

# ==================== æ–°å¢ä»£ç å¼€å§‹ ====================
# å®šä¹‰æ‰€æœ‰è¦åˆ é™¤çš„SOFAåˆ†é¡¹åˆ—
sofa_components_to_delete = [
    'sofa_resp', 
    'sofa_coag', 
    'sofa_liver', 
    'sofa_cardiovascular', 
    'sofa_cns', 
    'sofa_renal'
]

# æ‰¾å‡ºæ•°æ®ä¸­å®é™…å­˜åœ¨çš„ã€éœ€è¦åˆ é™¤çš„åˆ—
cols_to_drop = [col for col in sofa_components_to_delete if col in state_data.columns]

if cols_to_drop:
    # åˆ é™¤è¿™äº›åˆ—
    state_data.drop(columns=cols_to_drop, inplace=True)
    print(f"âœ… å·²æˆåŠŸåˆ é™¤ä»¥ä¸‹SOFAåˆ†é¡¹åˆ—: {cols_to_drop}")
    print(f"State data shape (åˆ é™¤å): {state_data.shape}")
else:
    print("â„¹ï¸ æœªæ‰¾åˆ°ä»»ä½•SOFAåˆ†é¡¹åˆ—ï¼Œæ— éœ€åˆ é™¤ã€‚")

# ==================== æ–°å¢ä»£ç ç»“æŸ ====================

print("è¯»å–å¤„æ–¹æ•°æ®...")
pres_data = pd.read_csv(PRES_CSV, 
                       usecols=['HADM_ID', 'STARTDATE', 'ENDDATE', 'DRUG'],
                       dtype={'HADM_ID': 'int32'},
                       parse_dates=['STARTDATE', 'ENDDATE'])
print(f"Prescription data shape: {pres_data.shape}")

print("è¯»å–æ”¹è¿›çš„è¯ç‰©æ˜ å°„...")
with open(DRUG_MAP_JSON, 'r') as f:
    drug_to_idx = json.load(f)
    
with open(DRUG_IDX_JSON, 'r') as f:
    drug_idx_info = json.load(f)

print(f"Drug mapping: {len(drug_to_idx)} drugs")
print(f"Drug categories: {drug_idx_info['num_drugs']} categories")

# æ­¥éª¤2ï¼šè¯ç‰©æ•°æ®æ¸…æ´—å’Œæ˜ å°„
print("\nğŸ§¹ æ­¥éª¤2ï¼šè¯ç‰©æ•°æ®æ¸…æ´—å’Œæ˜ å°„")

# ç›´æ¥æ˜ å°„åˆ°è¯ç‰©ç´¢å¼•
pres_data['drug_idx'] = pres_data['DRUG'].map(drug_to_idx)

# ä¸¢å¼ƒæœªæ˜ å°„çš„è¯ç‰©ï¼ˆdrug_idx == -1ï¼‰
pres_data = pres_data[pres_data['drug_idx'] != -1]
print(f"å¤„ç†åprescription data shape: {pres_data.shape}")

# è·å–æ‰€æœ‰å¯èƒ½çš„è¯ç‰©ç´¢å¼•
all_drug_indices = list(range(drug_idx_info['num_drugs']))
print(f"è¯ç‰©åŠ¨ä½œç»´åº¦: {len(all_drug_indices)}")

# æ­¥éª¤3ï¼šç”Ÿæˆæ—¶é—´çª—å£
print("\nğŸ—“ï¸ æ­¥éª¤3ï¼šç”Ÿæˆæ—¶é—´çª—å£")

# ä¸ºæ¯ä¸ªä½é™¢è®°å½•ç”Ÿæˆ24å°æ—¶æ—¶é—´çª—å£
# ç°åœ¨ä½¿ç”¨admittimeæ¥è®¡ç®—å®é™…çš„æ—¶é—´çª—å£
def get_time_windows(df):
    """ä¸ºæ¯ä¸ªstateè®°å½•ç”Ÿæˆæ—¶é—´çª—å£ï¼ˆåŸºäºadmittime + time_stepï¼‰"""
    windows = []
    for _, row in df.iterrows():
        # å°†admittimeè½¬æ¢ä¸ºdatetimeå¯¹è±¡
        admit_time = pd.to_datetime(row['admittime'])
        # æ¯ä¸ªtime_stepä»£è¡¨24å°æ—¶ï¼Œè®¡ç®—å®é™…æ—¶é—´çª—å£
        window_start = admit_time + pd.Timedelta(hours=24 * row['time_step'])
        window_end = admit_time + pd.Timedelta(hours=24 * (row['time_step'] + 1))
        
        windows.append({
            'hadm_id': row['hadm_id'],
            'time_step': row['time_step'],
            'admittime': admit_time,
            'window_start': window_start,
            'window_end': window_end
        })
    return pd.DataFrame(windows)

print("ç”Ÿæˆæ—¶é—´çª—å£...")
time_windows = get_time_windows(state_data[['hadm_id', 'time_step', 'admittime']])
print(f"æ—¶é—´çª—å£æ•°é‡: {len(time_windows)}")

# æ­¥éª¤4ï¼šè®¡ç®—è¯ç‰©ä½¿ç”¨æƒ…å†µ
print("\nğŸ’Š æ­¥éª¤4ï¼šè®¡ç®—è¯ç‰©ä½¿ç”¨æƒ…å†µ")

# åˆå¹¶å¤„æ–¹æ•°æ®å’Œæ—¶é—´çª—å£
pres_windows = pres_data.merge(time_windows, left_on='HADM_ID', right_on='hadm_id')

# åˆ¤æ–­è¯ç‰©æ˜¯å¦åœ¨æ—¶é—´çª—å£å†…ä½¿ç”¨
def is_drug_active(row):
    """åˆ¤æ–­è¯ç‰©æ˜¯å¦åœ¨æ—¶é—´çª—å£å†…æ´»è·ƒï¼ˆåŸºäºå®é™…æ—¶é—´å¯¹é½ï¼‰"""
    # æ£€æŸ¥è¯ç‰©çš„ä½¿ç”¨æ—¶é—´æ˜¯å¦ä¸æ—¶é—´çª—å£é‡å 
    drug_start = pd.to_datetime(row['STARTDATE'])
    drug_end = pd.to_datetime(row['ENDDATE'])
    window_start = pd.to_datetime(row['window_start'])
    window_end = pd.to_datetime(row['window_end'])
    
    # åˆ¤æ–­ä¸¤ä¸ªæ—¶é—´æ®µæ˜¯å¦æœ‰é‡å 
    # é‡å æ¡ä»¶ï¼šè¯ç‰©å¼€å§‹æ—¶é—´ < çª—å£ç»“æŸæ—¶é—´ AND è¯ç‰©ç»“æŸæ—¶é—´ > çª—å£å¼€å§‹æ—¶é—´
    return (drug_start < window_end) and (drug_end > window_start)

print("è®¡ç®—è¯ç‰©ä½¿ç”¨æƒ…å†µ...")
pres_windows['is_active'] = pres_windows.apply(is_drug_active, axis=1)

# ç­›é€‰æ´»è·ƒè¯ç‰©
active_drugs = pres_windows[pres_windows['is_active']]
print(f"æ´»è·ƒè¯ç‰©è®°å½•æ•°: {len(active_drugs)}")

# æ­¥éª¤5ï¼šæ„å»ºè¯ç‰©åŠ¨ä½œçŸ©é˜µ
print("\nğŸ“Š æ­¥éª¤5ï¼šæ„å»ºè¯ç‰©åŠ¨ä½œçŸ©é˜µ")

# èšåˆæ¯ä¸ªæ—¶é—´æ­¥çš„è¯ç‰©ä½¿ç”¨æƒ…å†µ
drug_usage = active_drugs.groupby(['hadm_id', 'time_step', 'drug_idx']).size().reset_index(name='count')

# è½¬æ¢ä¸ºäºŒè¿›åˆ¶çŸ©é˜µï¼ˆä½¿ç”¨æˆ–ä¸ä½¿ç”¨ï¼‰
drug_usage['used'] = 1

# åˆ›å»ºpivotè¡¨
drug_matrix = drug_usage.pivot_table(
    index=['hadm_id', 'time_step'],
    columns='drug_idx',
    values='used',
    fill_value=0
).reset_index()

# ç¡®ä¿æ‰€æœ‰è¯ç‰©ç´¢å¼•éƒ½å­˜åœ¨
for idx in all_drug_indices:
    if idx not in drug_matrix.columns:
        drug_matrix[idx] = 0

# é‡æ–°æ’åºåˆ—ï¼Œç¡®ä¿åˆ—åæ˜¯æ•´æ•°è€Œéå­—ç¬¦ä¸²
action_columns = ['hadm_id', 'time_step'] + sorted(all_drug_indices)
drug_matrix = drug_matrix[action_columns]

# å°†æ•°å­—åˆ—åè½¬æ¢ä¸ºæ•´æ•°
print("è½¬æ¢è¯ç‰©åŠ¨ä½œåˆ—åä»å­—ç¬¦ä¸²åˆ°æ•´æ•°...")
rename_dict = {}
for col in drug_matrix.columns:
    if col not in ['hadm_id', 'time_step']:
        rename_dict[col] = int(col)

drug_matrix = drug_matrix.rename(columns=rename_dict)
print(f"é‡å‘½ååçš„è¯ç‰©åŠ¨ä½œåˆ—å‰10ä¸ª: {list(drug_matrix.columns[2:12])}")

print(f"è¯ç‰©åŠ¨ä½œçŸ©é˜µ shape: {drug_matrix.shape}")

# æ­¥éª¤6ï¼šåˆå¹¶æ‰€æœ‰æ•°æ®
print("\nğŸ”— æ­¥éª¤6ï¼šåˆå¹¶æ‰€æœ‰æ•°æ®")

# åˆå¹¶stateæ•°æ®å’Œdrugæ•°æ®
final_dataset = state_data.merge(
    drug_matrix, 
    on=['hadm_id', 'time_step'], 
    how='left'
)

# å¡«å……ç¼ºå¤±çš„è¯ç‰©åŠ¨ä½œä¸º0
action_idx_cols = [col for col in sorted(all_drug_indices) if col in final_dataset.columns]
final_dataset[action_idx_cols] = final_dataset[action_idx_cols].fillna(0).astype('int8')

print(f"è¯ç‰©åŠ¨ä½œåˆ—æ•°é‡: {len(action_idx_cols)}")
print(f"è¯ç‰©åŠ¨ä½œåˆ—ç±»å‹: {type(action_idx_cols[0]) if action_idx_cols else 'None'}")
print(f"è¯ç‰©åŠ¨ä½œåˆ—å‰10ä¸ª: {action_idx_cols[:10]}")

# ä¸æ·»åŠ "æ— è¯ç‰©"æ ‡å¿—åˆ—ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…
# final_dataset['no_drug_action'] = (final_dataset[action_idx_cols].sum(axis=1) == 0).astype('int8')

print(f"æœ€ç»ˆæ•°æ®é›† shape: {final_dataset.shape}")
# è®¡ç®—æ— è¯ç‰©åŠ¨ä½œè®°å½•æ•°
no_drug_count = (final_dataset[action_idx_cols].sum(axis=1) == 0).sum()
print(f"æ— è¯ç‰©åŠ¨ä½œè®°å½•æ•°: {no_drug_count}")

# æ­¥éª¤7ï¼šæ•°æ®è´¨é‡æ£€æŸ¥
print("\nğŸ” æ­¥éª¤7ï¼šæ•°æ®è´¨é‡æ£€æŸ¥")

print("æ•°æ®è´¨é‡ç»Ÿè®¡:")
print(f"æ€»è®°å½•æ•°: {len(final_dataset)}")
print(f"å”¯ä¸€æ‚£è€…æ•°: {final_dataset['hadm_id'].nunique()}")
print(f"æ—¶é—´æ­¥èŒƒå›´: {final_dataset['time_step'].min()} - {final_dataset['time_step'].max()}")

# æ£€æŸ¥è¯ç‰©ä½¿ç”¨åˆ†å¸ƒ
drug_usage_stats = final_dataset[action_idx_cols].sum().sort_values(ascending=False)
print(f"æœ€å¸¸ç”¨çš„5ç§è¯ç‰©ç´¢å¼•: {drug_usage_stats.head().to_dict()}")

# æ­¥éª¤8ï¼šä¿å­˜ç»“æœ
print("\nğŸ’¾ æ­¥éª¤8ï¼šä¿å­˜ç»“æœ")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)

# ä¿å­˜æœ€ç»ˆæ•°æ®é›†
final_dataset.to_csv(OUTPUT_CSV, index=False)
print(f"âœ… è®­ç»ƒæ•°æ®é›†å·²ä¿å­˜åˆ°: {OUTPUT_CSV}")

# ä¿å­˜å…ƒæ•°æ®
metadata = {
    'dataset_shape': final_dataset.shape,
    'num_patients': int(final_dataset['hadm_id'].nunique()),
    'num_drug_actions': len(action_idx_cols),
    'time_step_range': [int(final_dataset['time_step'].min()), int(final_dataset['time_step'].max())],
    'drug_usage_stats': drug_usage_stats.head(10).to_dict(),
    'drug_mapping': drug_idx_info,
    'column_info': {
        'state_features': len(state_data.columns) - 2,  # å‡å»hadm_idå’Œtime_step
        'drug_actions': len(action_idx_cols),
        'total_columns': len(final_dataset.columns)
    },
    'action_column_info': {
        'action_columns': action_idx_cols,
        'action_column_type': str(type(action_idx_cols[0])) if action_idx_cols else 'None',
        'no_drug_records': int(no_drug_count)
    }
}

metadata_file = OUTPUT_CSV.replace('.csv', '_metadata.json')
with open(metadata_file, 'w') as f:
    json.dump(metadata, f, indent=2)

print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_file}")

print("\n" + "=" * 60)
print("è®­ç»ƒæ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
print("=" * 60)